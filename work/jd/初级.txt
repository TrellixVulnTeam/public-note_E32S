JDW(Jingdong Data Warehouse) 京东数据仓库
BDP(Big Data Platform) 大数据平台

业务篇：
    FDM 基础数据层
        * 增量表：
            分区：dt
            可以查询某日的增量数据。
        * 拉链表：
            分区：dp dt end_date
            使用start_date和end_date进行日期范围控制。
            获取date当天全量数据快照：start_date <= <date> and <date> < end_date
            拉链表的每个商品的记录基本上是不会变化的，若需要变化，则新建一个商品的记录，并将原记录置为expired。
            也就是说，拉链表的每个记录只有end_date和dp需要变更，其他字段变更则是通过新建记录的方式实现。
            因此，拉链表中保存了全部的数据快照，每个商品都能找到其在某个时间点的情况。
    BDM 通用数据层
    ADM 聚合数据层

HIVE:
    1.数据类型
        TINYINT
        SMALLINT
        INT
        BIGINT
        FLOAT
        DOUBLE
        BOOLEAN
        STRING
        DECIMAL
        为了更为灵活的使用，可以使用类型转换：
            select cast(<field>/<value> as double) from <table>; 将字段的数据强制转化为double
    2.建表
        1).元数据
            维护表定义的信息，和真实数据无关。比如表名，字段名，类型等等。
            保存在MySQL，可以是远程也可以是本地(这个本地指的是提供Hive Service的机器)。
        2).真实数据
            实际由用户管理的数据，比如学生表中的学生数据。
            保存在HDFS上，因此可以保存海量真实数据。
        3).压缩表/非压缩表
        4).内部表/外部表
            创建表时，指定EXTERNAL就是外部表，否则是内部表。
            内部表会在drop时从MySQL删除元数据从HDFS上删除数据。
            外部表不会再drop时删除数据。
            内部表：
                create table <tbname> ( ... ) [partitioned by (<field> <type>)] row format delimited fields terminated by '<char>' stored as TEXTFILE;
            外部表：
                create external table <tbname> ( ... ) ... location '<hdfs-path>';
    3.DML
        1).join
        2).过滤
        3).order by/sort by/distribute by/cluster by
        4).hive函数
            sysdate()、date_format()、concat、substr、like、split。
            sysdate()是hive特有的，用于指定相对于今天的日期。
        5).数据倾斜
        6).Hive分区表的高效查询
        7).多表插入
        8).hive null关联
        9).动态分区
            SET hive.exec.dynamic.partition=true;
            SET hive.exec.dynamic.partition.mode=nonstrict;
            可以启动动态分区。
            insert overwrite table <table> partition (dt)
                select * from <origin-table>
            当查询的结果里面有dt时，会动态的将对应的记录放在对应的分区中。
            静态分区时必须指定dt的值。
        10).数据采样

特别注意：
    一、union和union all
        union可以将两个查询结果合并成到一个结果中：
            SELECT column_name(s) FROM table_name1
            UNION
            SELECT column_name(s) FROM table_name2
        union操作符将会筛选掉重复的记录。如果允许重复的值，使用union all。
        JDH不支持union，仅仅支持union all。
        如果希望实现union的效果，需要使用子查询：
            select distinct * from ( ... union all ... ) tb;
    二、排序函数
        1.order by
            全局排序，因此只能有一个reduce，数据量较大时将会影响性能。
        2.sort by
            局部排序，多个reduce存在时，可以保证每个reduce输出的有序。
            常和distribute by联合使用。
        3.distribute by
            将指定的字段相同值交给同一个reduce。但是这并不代表该字段相同值的记录就完全占有一个reduce，而是确保这些相同的值在同一个reduce中。
            distribute by level 这样会将不同的level值交给不同的reduce。
            distribute by level sort by score asc。这样将会对相同的level记录的score值进行排序，因为这些相同的level记录都在同一个reduce中。
            level-1 1
            level-1 2
            level-1 3
            level-2 1
            level-2 3
            level-3 4
            level-3 5
        4.cluster by
            cluster by 是distribute by和sort by的结合，只能asc。
            cluster by level 等价于 distribute by level sort by level。
            其分组的字段和排序的字段是一样的，因此cluster by比较受限。
            （用了distribute by不代表一种类型的记录就占用一个reduce，在reduce少，而字段值类型多时，通过hash值和reduce求余进行分配，一个reduce里面应该会有好几种记录。因此需要这样的排序。）
    三、查询和Join优化
        0.根本思想
            尽早过滤数据，减少每个阶段的数据量(可以节约大量的网络传输和节点处理)
            减少Job数。复杂的hive任务会生成很多Job，而每个Job之间都是有依赖的，依赖的桥梁是每个Job在hdfs上生成的文件，因此过多的Job会耗费大量的IO。
            解决数据倾斜任务
        1.普通优化
            1).列裁剪
                将需要用到的列查询出来，不用的列就别查。
            2).分区裁剪
                也就是充分利用分区，如果有所属区的先验知识，则指定分区进行扫描。
                Explain dependency可以查看查询语句扫描的分区。
            3).多表插入优化
                insert overwrite table tmp1
                    select .... from tb where <cond1>
                insert overwrite table tmp2
                    select .... from tb where <cond2>
                将tb表中满足不同条件的数据输出到不同的表中，这样的方式会对tb表扫描多次。可以通过
                from tb
                    insert overwrite table tmp1
                        select ... where <cond1>
                    insert overwrite table tmp2
                        select ... where <cond2>
                这样的方式可以指定原始表仅来自于表tb，并且只会扫描tb一次。
            4).去重与排序
                尽量避免使用distinct进行去重。因为distinct会将所有的数据全部交给一个reduce，由这个reduce进行去重，这样会有严重的数据倾斜。
                使用group by来进行更好。
                传统：select distinct key from tb;
                优化：select key from tb group by key;
            2).小表在前，大表在后。
                因为reduce阶段，Join符号左边的表会被加载到内存中。这样可以有效的避免内存溢出。
            3).如果join多个表中的连接字段，都采用同一个，则join会转为单mapreduce任务，以减少job数。
            4).避免笛卡尔积，即一定要在on上加条件，并且连接的字段组合尽量唯一。
            5).join前过滤掉不需要的数据。
                传统方式 select * from A join B on .... where ... 这样的话会先连接在过滤，连接可能会影响性能。
                优化方式 select * from (select * from A where ...) tb1 join (select * from B where ...) tb2 on ....
                即通过子查询过滤掉不需要的数据，然后再连接。
        2.semi join
            通过semi join，可以高效实现in/exists子查询。
            传统方案：
                - select * from A where A.key in (select B.key from B);      将A.key和B.key进行连接。
                - select * from A left outer join B on A.key=B.key where B.key is not null;
            高效的方案:
                - select * from A left semi join B on A.key = B.key;
            B表有重复值的情况，semi join产生一条，join会产生多条。
        3.map join
            当大表与小表join时，可以采用map join，即将较小的表加载到每个mapper(大表数据所分布的mapper)的内存中，并省略掉reduce的步骤。这样做也可以避免数据倾斜。
        4.where子查询
            hive不能再where中写子查询，因此如果涉及到where中子查询需要改成用连接的方式来进行完成。
            原始: select * from tb1 where id = (select id from tb2 where ... limit 1)
            改进: 
                select *
                from tb1 a
                join (select id from tb2 where ... limit 1) b
                on a.id = b.id;
                上述中的limit 1并不是必须得，只是想强调该查询只有一条记录。
        5.列拼接显示
            如果希望将结果拼接在一起显示，也可以通过表连接的方式
            select a., b., c. ...
            from (select ... where ... limit 1) a
            join on (select ... where ... limit 1) b
            join on (select ... where ... limit 1) c
            ...
            上述中的limit 1并不是必须得，只是想强调该查询只有一条记录。
                
考题整理以及不明白的地方：
    1.关于hadoop map/reduce正确的是?
        reduce的数量必须大于零
        reduce总是在所有map完成之后再执行
        * combiner 过程实际也是 reduce过程
        Mapper的数量由输入的文件个数决定
    2.hive查询语言和sql的一个不同之处在于
        group by
        join
        partition
        union
    3.dual与select表达式
        这是一个虚拟表，没有实际意义，oracle中也有这种表的存在。
        主要是为了测试select中的表达式，但是由于select表达式必须保持完整所以要使用dual表。
        select 2+3, 2.0+3 from dual; 用于测试表达式的值。
        需要注意的是 cast(number as boolean)，这里数字number非0返回true，否则返回false。
    4.全量表、增量表与拉链表的区分以及使用
        FDM层分为【增量表】和【拉链表】，命名规则: fdm_源库名称_源表名_加载策略
            这里，增量表的加载策略为空，拉链表的加载策略为chain。
            fdm层增量表
            fdm层拉链表 以end_date、dp和dt进行分区
                对于每个item，都以一条拉链的形式存在于表中，拉链中的一节就是表中的一行记录。
                每个item的key都是相同的，以标记他们都是属于该item或是说都是属于某条拉链。
                每当item的数据发生变化的时候，拉链都会新增一节以表示最新的数据，从数据库的角度来看就是在表中新增了一条记录，该记录中保存了该item的最新属性。
                该表中的分区字段:
                    end_date是记录属性的结束时间，这个时间以后属性就变了，该记录后item属性没有发生变化，那么end_date为4712-12-31.
                    dp是记录的状态，active描述记录是item的当前使用的属性，expired描述记录是item已经没有使用的属性，即过期属性。
                    dt是记录修改时间，一般和end_date的值相同。
        GDM层分为【增量表】和【全量表】，命名规则: gdm_主题前缀_主体[_DA]
            这里，增量表没有_DA，全量表最后含_DA。
            gdm层全量表
                每天都有整个记录的拷贝，冗余很大，高可用。
                比如某天的数据包括 该天以前的数据 再加上 该天新增的数据。
            gdm层增量表
                分为两种增量表:
                1).以dt为分区
                    dt代表记录创建时间。
                2).以dt和dp分区
                    dp代表是否归档，history为归档，active为未归档。
                    dt代表记录的归档时间，若未归档dt为4712-12-31。
                    不同的业务增量表，新增->归档的周期是不同的 一般为30/90/180天。
                    对于此类表，可以观察到查询某天的记录需要用dt>='某天' and date='某天'。
                    这里使用dt的原因是为了分区加速查询，而dt代表的是归档时间，只有在创建记录以后才会归档，因此归档时间会大于某天，因此采用>=。
    5.hql优化案例
        1).先过滤再连接
            SELECT a.id, b.name 
            FROM a 
            LEFT OUTER JOIN b 
            ON a.id = b.id 
            WHERE a.dt=’2013-01-01’ AND b.dt = ‘2013-01-01’;
            改
            select x.id, y.name
            from ( select * from a where a.dt='2013-01-01' ) x
            left outer join ( select * from b where b.dt='2013-01-01') y
            on x.id = y.id
    6.hql使用案例
        1).订单汇总表exam_gdm_m04_ord_sum。从该表中查出2014年3月29日下单的的铜牌会员人数。
            select count(distinct user_id) 
            from exam_gdm_m04_ord_sum
            where dt >= '2014-03-29' and ord_dt = '2014-03-29' and user_lv_cd = '56' and valid_flag = 1;
            必须使用dt是因为dt可以进行分区，加快查询。
            一个铜牌会员可能会下多次单，因此需要用distinct user_id去重。
        2).exam_dim表保存着了当前id，父亲id，当前点名字。做线性维表。
            i).低效
                select t1.id, t1.name, t2.id, t2.name, t3.id, t3.name
                from exam_dim t1
                join exam_dim t2 on t2.father_id = t1.id
                join exam_dim t3 on t3.father_id = t2.id;
            ii).先过滤出省，这样更高效
                select t1.id as province_id,t1.name as province_name, t2.id as city_id,t2.name as city_name,t3.id as county_id,t3.name as county_name
                from (select * from exam_dim where father_id=0) as t1 
                join exam_dim as t2 on t2.father_id = t1.id
                join exam_dim as t3 on t3.father_id = t2.id;
            这样的表本质上保存了一个树形结构，而每条记录其实是一个记录了父id的节点。当已知该该树形结构的层数，则可以求出所有从根节点到叶子节点的路径。
            并且这样的表需要满足：所有的叶子节点深度一致。
        3).查出2014年3月29日中有效下单量，出库订单量，完成订单量
            i).
                select
                    count(distinct if(to_date(ord_tm) = '2014-03-29', sale_ord_id, ''))   as 有效下单量,
                    count(distinct if(to_date(out_wh_tm) = '2014-03-29', sale_ord_id, '')) as 出库订单量,
                    count(distinct if(to_date(ord_complete_tm) = '2014-03-29', sale_ord_id, '')) as 完成订单
                from
                    exam_gdm_m04_ord_sum
                where dt >= '2014-03-29' and valid_flag = ' 1'
            ii).
                select

                from (
                    select count()
                    from exam_gdm_m04_ord_sum
                    where dt>= '2014-03-29' and valid_flag = '1' and ord_dt = '2014-03-29'
                ) a
                left outer join (
                    select

                ) b
                left outer join (
                    select
                ) c

        4).获取某天的所有订单量和父订单量
            select count(id) as idNum, count(distinct parentid) as pidNum 
            from fdm_pek_orders_chain 
            where start_date <= '2014-12-15' and end_date > '2014-12-15' and yn = 1 and to_date(createdate) = '2014-12-15' and parentid is not null
            这是一个拉链表，因此要采用start_date和end_date去获取某天快照。
        6).表gdm_m04_ord_det_sum 。从该表中查出 在销量最大的第一分类中，其第二分类的销量，并降序排序。
            select a.item_first_cate_cd, a.item_first_cate_name, a.item_second_cate_cd, a.item_second_cate_name, sum(a.sale_qtty) as total
            from gdm_m04_ord_det_sum a
            join (
                select item_first_cate_cd, item_first_cate_name, sum(sale_qtty) as total
                from gdm_m04_ord_det_sum 
                where dt>='2014-11-11' and sale_ord_valid_flag='1'
                group by item_first_cate_cd, item_first_cate_name
                order by total desc
                limit 1
            ) b
            on a.item_first_cate_cd = b.item_first_cate_cd
            where dt>='2014-11-11' and sale_ord_valid_flag='1'
            group by a.item_first_cate_cd, a.item_first_cate_name, a.item_second_cate_cd, a.item_second_cate_name
            order by total desc;
            表b是查询得到的销量最大的第一分类的id和名称信息，和原始表做连接以过滤出销量最大的第一分类所有信息。
            这是将where中子查询转换为连接的方式进行处理的案例。